"""
Author: Navid Shervani-Tabar
"""
import torch
import pickle
import torch.optim as optim

from torch.utils.data import DataLoader
from torch import nn

from VAEmodel import VAEmod
from utils import tools, MolecularGraphDataset as MGD

class VAEgraph(object):
    def __init__(self, args):

        # -- training parameters
        self.device = args.device
        self.epochs = args.epochs
        self.batch_size = args.batch_size
        self.dataset_name = args.data_dir
        self.res_dir = args.res_dir
        self.N     = args.N
        self.N_vis = args.N_vis
        self.log_interval = args.log_interval
        self.n_samples = args.n_samples
        self.vis = args.vis
        self.mu_reg_1 = args.mu_reg_1
        self.mu_reg_2 = args.mu_reg_2
        self.mu_fcn = 70

        self.train_hist = {}
        for file in ['Tl', 'KL', 'RC', 'R1', 'R2']:
            self.train_hist[file] = []

        # -- model loading parameters
        self.filemodel = args.loadtrainedmodel
        self.loadmodel = bool(self.filemodel)

        # -- graph parameters
        self.n_atom_features = args.n_atom_type
        self.n_bond_features = args.n_bond_type
        self.n_node = args.n_node

        # -- set seed
        if not args.seed == 0:
            torch.manual_seed(args.seed)
            if bool(args.gpu_mode):
                torch.cuda.manual_seed(args.seed)

        # -- network setting
        self.z_dim = args.z_dim
        self.TrainDataset = DataLoader(dataset=MGD(self.dataset_name, self.N, 0), batch_size=self.batch_size, shuffle=False)
        self.VisulDataset = DataLoader(dataset=MGD(self.dataset_name, self.N_vis, self.N), batch_size=self.N_vis, shuffle=False)

        self.model = VAEmod(args).to(self.device)
        self.optimizer = optim.Adam(self.model.parameters(), lr=1e-3)

        self.tools = tools(args)

    def constraints(self, reg_sig, reg_adj, batch_dim):
        """
            physical constraints.
        :param reg_sig: signal generated by sampling from latent space.
        :param reg_adj: adjacency generated by sampling from latent space.
        :param batch_dim: batch size.
        :return: regularization terms.
        """

        # -- Constraint: Ghost Nodes and Valence
        SM_f = nn.Softmax(dim=2)
        SM_W = nn.Softmax(dim=3)

        p_f = SM_f(reg_sig)
        p_W = SM_W(reg_adj)

        h_vec = torch.arange(self.n_bond_features, device=self.device).float()
        inner_sum = torch.einsum('i,bjki->bjk', h_vec, p_W)
        V = (inner_sum - torch.diag_embed(torch.einsum('...ii->...i', inner_sum))).sum(2)

        valence_dict = torch.Tensor([4, 2, 3, 1, 0]).to(self.device)
        U = torch.einsum('k,bjk->bj', valence_dict, p_f)

        reg_1 = torch.mean(torch.max(torch.zeros(U.size(), device=self.device), V - U).sum(1))

        # -- Constraint: Connectivity
        Sig = nn.Sigmoid()

        q = 1 - p_f[:, :, 4]
        A = 1 - p_W[:, :, :, 0]

        A_0 = torch.eye(self.n_node).unsqueeze(0)
        A_i = A

        B = A_0.repeat(reg_sig.size(0), 1, 1).to(self.device)

        for i in range(1, self.n_node):
            A_i = Sig(100 * (torch.bmm(A_i, A) - 0.5))
            B += A_i

        C = Sig(100 * (B - 0.5))
        reg_2 = 1./batch_dim*torch.sum( torch.einsum('ij,ik,ijk->ijk', q, q, 1 - 2 * C)+ C )

        return [reg_1, reg_2]

    def loss_function(self, recon_sig, recon_adj, weight_vec, signal, adj, reg_sig, reg_adj, mu, logvar):

        batch_dim = recon_sig.shape[0]

        target_sig = signal.reshape(-1, self.n_node, self.n_atom_features).view(-1, self.n_atom_features).argmax(1)
        target_adj = adj.view(-1)

        output_adj = recon_adj.reshape(-1, self.n_bond_features)
        output_sig = recon_sig.reshape(-1, self.n_atom_features)

        atm_class_weights = None
        loss_sig = torch.nn.CrossEntropyLoss(weight=atm_class_weights, reduction='none')

        bnd_class_weights = None
        loss_adj = torch.nn.CrossEntropyLoss(weight=bnd_class_weights, reduction='none')
        fcn_loss_1 = loss_sig(output_sig, target_sig.long()).view(-1, self.n_node)

        fcn_loss_2 = loss_adj(output_adj, target_adj.long()).view(-1, self.n_node, self.n_node)
        fcn_loss_2 = torch.triu(fcn_loss_2, diagonal=1)

        fcn_loss = 1./ self.n_node * torch.mean(fcn_loss_1, 1) + 2 * self.n_node ** 2 / (self.n_node * (self.n_node - 1)) * torch.mean(fcn_loss_2, [1, 2])
        KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp(), 1)

        [reg_1, reg_2] = self.constraints(reg_sig, reg_adj, batch_dim)

        loss = self.N / batch_dim * (self.mu_fcn * torch.dot(fcn_loss, weight_vec) + torch.dot(KLD, weight_vec)) + \
               (self.mu_reg_1 * reg_1 + self.mu_reg_2 * reg_2)

        self.train_hist['Tl'].append(loss)
        self.train_hist['RC'].append(self.N / batch_dim * self.mu_fcn * torch.dot(fcn_loss, weight_vec))
        self.train_hist['KL'].append(self.N / batch_dim * torch.dot(KLD, weight_vec))
        self.train_hist['R1'].append(self.mu_reg_1 * reg_1)
        self.train_hist['R2'].append(self.mu_reg_2 * reg_2)

        return loss

    def trainepoch(self, epoch):

        self.model.train()
        train_loss = 0
        for batch_idx, (train_batch, weight_vec) in enumerate(zip(self.TrainDataset, self.weights_loader)):
            train_batch['signal'] = train_batch['signal'].to(self.device)
            train_batch['adjacency'] = train_batch['adjacency'].to(self.device)

            self.optimizer.zero_grad()

            [rec_sig, rec_adj], mu, logvar, [reg_sig, reg_adj] = self.model(train_batch['signal'], train_batch['adjacency'])
            loss = self.loss_function(rec_sig, rec_adj, weight_vec, train_batch['signal'], train_batch['adjacency'], reg_sig, reg_adj, mu, logvar)
            loss.backward()
            train_loss += loss.item()

            self.optimizer.step()

        print('Train Epoch: {}\tLoss: {:.6f}'.format(epoch, train_loss/len(self.TrainDataset.dataset)))

    def train(self, weights, model_name = '/model.pth'):

        if not self.loadmodel:
            self.weights_loader = DataLoader(weights.to(self.device), batch_size=self.batch_size, shuffle=False)
            for epoch in range(1, self.epochs + 1):
                self.trainepoch(epoch)

                if self.vis and epoch % self.log_interval == 0:
                    self.tools.visLatent(self.VisulDataset, self.model, epoch)

                if self.vis and epoch == self.epochs:
                    self.tools.pltLoss(self.train_hist, epoch)

            torch.save(self.model, self.res_dir + model_name)

        else:
            self.model = torch.load(self.filemodel + model_name)

        if self.vis:
            self.tools.visLatent(self.VisulDataset, self.model, self.epochs, TrainData=self.TrainDataset, EndPts=(14, 200))
        self.model.eval()

    def get_samples(self, sample_name='/samples.data'):
        self.model.eval()
        with torch.no_grad():
            sample_z = torch.randn((self.n_samples, self.z_dim), device=self.device)

        samplesTorch = self.model.decode(sample_z)

        with torch.no_grad():
            samples_sig = torch.argmax(samplesTorch[0], dim=2)
            samples_adj = torch.argmax(samplesTorch[1], dim=3)
            samples_adj = samples_adj - torch.diag_embed(torch.einsum('...ii->...i', samples_adj))

        # -- store the samples
        with open(self.res_dir + sample_name, 'wb') as f:
            pickle.dump(samples_sig, f)
            pickle.dump(samples_adj, f)
            pickle.dump(sample_z, f)

        return samples_sig, samples_adj, sample_z
